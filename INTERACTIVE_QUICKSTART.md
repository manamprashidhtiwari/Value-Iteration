# ğŸš€ INTERACTIVE VALUE ITERATION - QUICK START

## âœ… What's New - Interactive Setup!

Now you can **configure everything interactively**:
- âœ… Grid dimensions (user input!)
- âœ… Goal state position
- âœ… Fire state (optional)
- âœ… Obstacles (as many as you want)
- âœ… Start state (optional, for visualization)
- âœ… Algorithm parameters (Î³, Î¸, max iterations)

**No more editing config files!** Just run and answer questions.

---

## ğŸ“¦ Files Overview

| File | Purpose | New? |
|------|---------|------|
| **input_handler.py** | Interactive user input | âœ… NEW |
| **config_dynamic.py** | Dynamic configuration | âœ… NEW |
| **config.py** | Static config (backup) | Old |
| **environment.py** | Grid world logic | Updated |
| **value_iteration.py** | Core algorithm | Updated |
| **visualizer.py** | Plots and animations | Updated |
| **main.py** | Interactive runner | âœ… NEW |

---

## ğŸ¯ How to Run

### Step 1: Install dependencies
```bash
pip install matplotlib numpy
```

### Step 2: Run the program
```bash
python main.py
```

### Step 3: Answer the questions!

---

## ğŸ“ Example Session

```
======================================================================
   VALUE ITERATION - INTERACTIVE SETUP
======================================================================

Note: Grid uses 0-based indexing
Example: For a 4x4 grid, states are from (0,0) to (3,3)

==================================================
   GRID SETUP
==================================================

Enter grid dimensions (rows cols): 4 4
âœ… Grid size: 4x4

ğŸ“ Goal State (reward: +1)
Enter goal state (row col): 0 3
âœ… Goal: (0, 3)

ğŸ”¥ Fire State (reward: -1) [Optional]
Do you want a fire state? (yes/no) [no]: yes
Enter fire state (row col): 1 3
âœ… Fire: (1, 3)

ğŸš§ Obstacles [Optional]
Do you want obstacles? (yes/no) [no]: yes
Enter obstacles one by one. Press Enter without input when done.
Obstacle 1 (row col) or [Enter to finish]: 1 1
âœ… Obstacle 1 added: (1, 1)
Obstacle 2 (row col) or [Enter to finish]: 
âœ… Total obstacles: 1

ğŸ¯ Start State [Optional]
Do you want to specify a start state? (yes/no) [no]: yes
Enter start state (row col): 3 0
âœ… Start: (3, 0)

==================================================
   ALGORITHM PARAMETERS
==================================================

Enter discount factor Î³ (0-1) [0.9]: 0.9
âœ… Gamma (Î³): 0.9
Enter convergence threshold Î¸ [0.001]: 0.001
âœ… Theta (Î¸): 0.001
Enter maximum iterations [100]: 50
âœ… Max iterations: 50

======================================================================
   CONFIGURATION SUMMARY
======================================================================
Grid Size:        4x4
Goal State:       (0, 3) (reward: +1)
Fire State:       (1, 3) (reward: -1)
Obstacles:        [(1, 1)]
Start State:      (3, 0)
Discount (Î³):     0.9
Threshold (Î¸):    0.001
Max Iterations:   50
======================================================================

Proceed with this configuration? (yes/no) [yes]: yes

======================================================================
   RUNNING VALUE ITERATION
======================================================================

âœ… Environment created: 4x4 Grid
   Goal: (0, 3) | Fire: (1, 3) | Obstacles: 1

--- Value Iteration Started ---

Iteration 1: max_change = 1.000000
Iteration 2: max_change = 0.900000
Iteration 3: max_change = 0.810000
Iteration 4: max_change = 0.729000
Iteration 5: max_change = 0.656100
Iteration 6: max_change = 0.590490
Iteration 7: max_change = 0.000000

âœ… Converged after 7 iterations!
   (Convergence threshold Î¸ = 0.001)

ğŸ“Š Total iterations completed: 7

======================================================================
   FINAL RESULTS
======================================================================

Value Function:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  0.810 â”‚  0.900 â”‚  1.000 â”‚  0.000 â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  0.729 â”‚  0.000 â”‚  0.900 â”‚  0.000 â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  0.656 â”‚  0.729 â”‚  0.810 â”‚  0.729 â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  0.590 â”‚  0.656 â”‚  0.729 â”‚  0.656 â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Optimal Policy:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ â†’  â”‚ â†’  â”‚ â†’  â”‚ G  â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ â†‘  â”‚ X  â”‚ â†‘  â”‚ F  â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ â†‘  â”‚ â†’  â”‚ â†‘  â”‚ â†  â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ â†‘  â”‚ â†‘  â”‚ â†‘  â”‚ â†‘  â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

======================================================================
   VISUALIZATION OPTIONS
======================================================================

1. Animation of all iterations
2. Final value function heatmap
3. Optimal policy with arrows
4. All of the above
5. Skip visualizations

Select visualization (1-5) [4]: 4

ğŸ“Š Generating visualizations...
   - Creating animation...
   - Creating value function plot...
   - Creating policy plot...

======================================================================
   âœ… VALUE ITERATION COMPLETE!
======================================================================

ğŸ“Š Summary:
   Total iterations: 7
   Grid size: 4x4
   States processed: 15
   Discount factor (Î³): 0.9
   Convergence threshold (Î¸): 0.001

   Thank you for using Value Iteration! ğŸ‰
```

---

## âš™ï¸ Input Guide

### Grid Dimensions
```
Enter grid dimensions (rows cols): 5 5
```
- Minimum: 2x2
- Maximum: 20x20

### Goal State
```
Enter goal state (row col): 0 4
```
- Required
- Must be within grid bounds
- Receives reward of +1

### Fire State
```
Do you want a fire state? (yes/no) [no]: yes
Enter fire state (row col): 2 4
```
- Optional
- Receives reward of -1
- Cannot be same as goal

### Obstacles
```
Do you want obstacles? (yes/no) [no]: yes
Obstacle 1 (row col) or [Enter to finish]: 1 1
Obstacle 2 (row col) or [Enter to finish]: 2 2
Obstacle 3 (row col) or [Enter to finish]: 
```
- Optional
- Add as many as you want
- Cannot overlap with goal/fire
- Press Enter alone to finish

### Start State
```
Do you want to specify a start state? (yes/no) [no]: yes
Enter start state (row col): 4 0
```
- Optional
- Only used for visualization/understanding
- Algorithm finds optimal policy for ALL states

### Algorithm Parameters

**Discount Factor (Î³):**
```
Enter discount factor Î³ (0-1) [0.9]: 0.95
```
- Range: 0 to 1
- Higher = more far-sighted
- Default: 0.9

**Convergence Threshold (Î¸):**
```
Enter convergence threshold Î¸ [0.001]: 0.0001
```
- Smaller = more precise
- Larger = faster convergence
- Default: 0.001

**Maximum Iterations:**
```
Enter maximum iterations [100]: 200
```
- Safety limit to prevent infinite loops
- Algorithm stops early if converged
- Default: 100

---

## ğŸ¨ Visualization Options

After algorithm runs, choose what to see:

1. **Animation** - Watch values converge iteration by iteration
2. **Final heatmap** - See final value function as colored grid
3. **Policy arrows** - See optimal actions with arrows (â†‘â†“â†â†’)
4. **All of the above** - Show everything (recommended!)
5. **Skip** - Just see text output

---

## ğŸ’¡ Quick Examples

### Example 1: Small Grid
```
Dimensions: 3 3
Goal: 0 2
Fire: no
Obstacles: no
Start: 2 0
Î³: 0.9
Î¸: 0.001
Max iterations: 50
```

### Example 2: Maze-like Grid
```
Dimensions: 5 5
Goal: 0 4
Fire: yes â†’ 2 4
Obstacles: yes â†’ (1,1), (1,2), (2,2), (3,2)
Start: 4 0
Î³: 0.9
Î¸: 0.001
Max iterations: 100
```

### Example 3: Large Grid
```
Dimensions: 10 10
Goal: 0 9
Fire: yes â†’ 5 9
Obstacles: yes â†’ add a few scattered
Start: 9 0
Î³: 0.95
Î¸: 0.0001
Max iterations: 200
```

---

## ğŸ”§ Understanding Start State

**Important:** The start state is **optional** and only affects visualization.

- **What it does:** Shows you where an agent might begin
- **What it doesn't do:** Doesn't change the algorithm
- **Why?** Value Iteration finds the optimal policy for **ALL states**, not just one

**In the animation:** If you specify a start state, it helps you trace the path from start to goal.

---

## ğŸ“Š Understanding the Output

### Iteration Count
```
Iteration 1: max_change = 1.000000
Iteration 2: max_change = 0.900000
...
Iteration 7: max_change = 0.000000

âœ… Converged after 7 iterations!
ğŸ“Š Total iterations completed: 7
```

Shows how values changed each iteration and when convergence happened.

### Value Function
```
â”‚  0.810 â”‚  0.900 â”‚  1.000 â”‚  0.000 â”‚
```
- Higher values = better states
- Goal state: always shows final reward
- Fire state: always shows penalty

### Policy Grid
```
â”‚ â†’  â”‚ â†’  â”‚ â†’  â”‚ G  â”‚
â”‚ â†‘  â”‚ X  â”‚ â†‘  â”‚ F  â”‚
```
- Arrows (â†‘â†“â†â†’) = optimal action
- G = Goal
- F = Fire
- X = Obstacle

---

## ğŸ› Troubleshooting

### "Out of bounds" error
- Check your grid size
- State indices start at 0
- For 4x4 grid: valid states are (0,0) to (3,3)

### Values not converging
- Increase max_iterations
- Check that goal is reachable
- Try larger Î¸ for faster (less precise) convergence

### No visualization showing
- Make sure matplotlib is installed
- Try option 5 (skip) to see text only
- Check for errors in console

---

## ğŸ“ Learning Tips

1. **Start simple:** Try 3x3 grid first
2. **Watch convergence:** See how values propagate from goal
3. **Experiment with Î³:** See how it affects policy
4. **Add obstacles:** See how policy routes around them
5. **Compare iterations:** Watch the animation carefully

---

## ğŸš€ Next Steps

After mastering interactive setup:

1. Try different grid sizes
2. Experiment with Î³ values
3. Create complex mazes with obstacles
4. Compare convergence speeds
5. Implement Policy Iteration next!

---

## ğŸ“ Key Features

âœ… **Fully interactive** - No file editing needed  
âœ… **Error handling** - Validates all inputs  
âœ… **Flexible** - Fire and obstacles are optional  
âœ… **User-friendly** - Clear prompts and defaults  
âœ… **Iteration tracking** - Shows convergence progress  
âœ… **Multiple visualizations** - Choose what you want to see  

---

**Perfect for your practical! Professional, interactive, and easy to demonstrate! ğŸ‰**

Run `python main.py` and enjoy! ğŸš€
